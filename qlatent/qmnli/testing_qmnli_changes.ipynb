{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlatent.qmnli.qmnli import _QMNLI, SCALE\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "    'never':-4,\n",
    "    'very rarely':-3,\n",
    "    'seldom':-2,\n",
    "    'rarely':-2,\n",
    "    'frequently':2,\n",
    "    'often':2,\n",
    "    'very frequently':3,\n",
    "    'always':4,    \n",
    "}\n",
    "\n",
    "class GAD7Q1(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I feel {emotion}.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['nervous', 'anxious', 'on edge'],\n",
    "            emo_neg=['calm', 'peaceful', 'relaxed'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":1,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Feeling nervous, anxious or on edge'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q2(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I was {emotion}.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['nervous', 'bothered', 'disturbed'],\n",
    "            emo_neg=['peaceful','calm', 'relaxed'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "              \"Factor\":\"GAD\",\n",
    "              \"Ordinal\":2,\n",
    "              \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Not being able to stop or control worrying'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q3(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I felt {emotion} about different things.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['worryied', 'stressed', 'nervous'],\n",
    "            emo_neg=['confident', 'tranquil'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":3,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Worrying too much about different things'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q4(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I've been having {emotion} relaxing.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['trouble', 'difficulty', ],\n",
    "            emo_neg=['no problem', 'an easy time'],\n",
    "\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":4,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Trouble relaxing'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q5(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I felt {emotion}.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['restless', 'agitated', 'nervous'],\n",
    "            emo_neg=['calm', 'tranquil', 'relaxed'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":5,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Being so restless that it is hard to sit still'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q6(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I became {emotion}.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['annoyed', 'irritated', 'frustrated', 'bothered'],\n",
    "            emo_neg=['calm', 'tranquil', 'peaceful', 'relaxed'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":6,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Becoming easily annoyed or irritable'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "class GAD7Q7(_QMNLI):\n",
    "  \n",
    "    index = [\"emotion\"] \n",
    "    scale = \"intensifier\"\n",
    "\n",
    "  \n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            context=\"Over the last 2 weeks, I felt {emotion} about upcoming events.\",\n",
    "            template=\"It is {intensifier} correct.\",\n",
    "            emo_pos=['afraid', 'scared'],\n",
    "            emo_neg=['calm', 'tranquil', 'relaxed'],\n",
    "            intensifiers=frequency_weights,\n",
    "            descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                      \"Factor\":\"GAD\",\n",
    "                      \"Ordinal\":7,\n",
    "                      \"Original\":'Over the last 2 weeks, how often have you been bothered by the following problems? Feeling afraid as if something awful might happen'\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "gad2_qmnli = [GAD7Q1, GAD7Q2]\n",
    "gad7_qmnli = [GAD7Q1, GAD7Q2, GAD7Q3, GAD7Q4, GAD7Q5, GAD7Q6, GAD7Q7]\n",
    "gad_qmnli = gad7_qmnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from tqdm.auto import tqdm\n",
    "from qlatent.qmnli.qmnli import *\n",
    "from qlatent.qmnli.qmnli import _QMNLI, QMNLI\n",
    "# importlib.reload(_QMNLI)\n",
    "\n",
    "import torch\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_files = [False, True]\n",
    "# softmax_files = [True]\n",
    "\n",
    "def split_question(Q, index, scales, softmax, filters):\n",
    "  result = []\n",
    "  for s in scales:\n",
    "    q = QCACHE(Q(index=index, scale=s))\n",
    "    for sf in softmax:\n",
    "      for f in filters:\n",
    "        if sf:            \n",
    "            qsf = QSOFTMAX(q,dim=[index[0], s])\n",
    "            qsf_f = QFILTER(qsf,filters[f],filtername=f)\n",
    "            print((index, s),sf,f)\n",
    "            result.append(qsf_f)\n",
    "            \n",
    "#             qsf = QSOFTMAX(q,dim=s)\n",
    "#             qsf_f = QFILTER(qsf,filters[f],filtername=f)\n",
    "#             print(s,sf,f)\n",
    "#             result.append(qsf_f)\n",
    "            \n",
    "#             qsf = QSOFTMAX(q,dim=index[0])\n",
    "#             qsf_f = QFILTER(qsf,filters[f],filtername=f)\n",
    "#             print(index[0],sf,f)\n",
    "#             result.append(qsf_f)\n",
    "        else:\n",
    "            qsf = QPASS(q,descupdate={'softmax':''})\n",
    "            qsf_f = QFILTER(qsf,filters[f],filtername=f)\n",
    "            print(s,sf,f)\n",
    "            result.append(qsf_f)\n",
    "  return result\n",
    "\n",
    "def dict_pos_neg(pos, neg, w):\n",
    "  return dict(dict_same_weight(1.0*w/len(pos),pos), **dict_same_weight(-1.0*w/len(neg),neg))\n",
    "\n",
    "def print_permutations(q):\n",
    "#     for q in Q1s:\n",
    "    W = q._pdf['W']\n",
    "    print(q._descriptor)\n",
    "    for i, (kmap, w) in enumerate(zip(q._keywords_map, W)):\n",
    "        context = q._context_template.format_map(kmap)\n",
    "        answer = q._answer_template.format_map(kmap)\n",
    "#         sexisem_score = sexisem_classifier(context.strip('.') + ' ' +answer)\n",
    "        print(f'{i}.',context ,'->', answer, w)\n",
    "#     break\n",
    "\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "    'never':-4,\n",
    "    'very rarely':-3,\n",
    "    'seldom':-2,\n",
    "    'rarely':-2,\n",
    "    'frequently':2,\n",
    "    'often':2,\n",
    "    'very frequently':3,\n",
    "    'always':4,    \n",
    "}\n",
    "    \n",
    "    \n",
    "binary_frequency_weights = {k: 1 if v > 0 else -1 for k, v in frequency_weights.items()}\n",
    "rbinary_frequency_weights = {k: -1 if v > 0 else 1 for k, v in frequency_weights.items()}\n",
    "frequency_pos = [k for k, v in frequency_weights.items() if v > 0]\n",
    "frequency_neg = [k for k, v in frequency_weights.items() if v < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "# p = 'valhalla/distilbart-mnli-12-6'\n",
    "p = \"typeform/distilbert-base-uncased-mnli\"\n",
    "mnli = pipeline(\"zero-shot-classification\",device=device, model=p)\n",
    "mnli.model_identifier = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['emotion'], 'intensifier') True unfiltered\n",
      "(['emotion'], 'intensifier') True positiveonly\n",
      "1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m Qs \u001b[38;5;241m=\u001b[39m split_question(Q,\n\u001b[0;32m      3\u001b[0m                     index\u001b[38;5;241m=\u001b[39mQ\u001b[38;5;241m.\u001b[39mindex,\n\u001b[0;32m      4\u001b[0m                     scales\u001b[38;5;241m=\u001b[39m[Q\u001b[38;5;241m.\u001b[39mscale],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m                             },\n\u001b[0;32m      9\u001b[0m                     )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(Qs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_descriptor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrdinal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mQs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnli\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreport()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:626\u001b[0m, in \u001b[0;36mQFILTER.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;129m@overrides\u001b[39m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 626\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    628\u001b[0m     select \u001b[38;5;241m=\u001b[39m _filter_data_frame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:541\u001b[0m, in \u001b[0;36mQDELEGATOR.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;129m@overrides\u001b[39m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;66;03m#print(f\"{self.__class__.__name__} delgates execution of run(..) to {self._run.__self__.__class__.__name__}\" )\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(result\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m#retain self._descriptor and self._run\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:598\u001b[0m, in \u001b[0;36mQSOFTMAX.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;129m@overrides\u001b[39m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 598\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dim, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_temperature)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:541\u001b[0m, in \u001b[0;36mQDELEGATOR.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;129m@overrides\u001b[39m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;66;03m#print(f\"{self.__class__.__name__} delgates execution of run(..) to {self._run.__self__.__class__.__name__}\" )\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(result\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m#retain self._descriptor and self._run\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:570\u001b[0m, in \u001b[0;36mQCACHE.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached \u001b[38;5;129;01mand\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodel_identifier \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_model_identifier:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;66;03m# print(f\"Skipping model execution. Use cached results.\")\u001b[39;00m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 570\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_model_identifier \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmodel_identifier\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qabstract\\qabstract.py:541\u001b[0m, in \u001b[0;36mQDELEGATOR.run\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;129m@overrides\u001b[39m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;66;03m#print(f\"{self.__class__.__name__} delgates execution of run(..) to {self._run.__self__.__class__.__name__}\" )\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(result\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m)\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m#retain self._descriptor and self._run\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qmnli\\qmnli.py:82\u001b[0m, in \u001b[0;36mQMNLI.run\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m## Calculate batch entailment probabilities\u001b[39;00m\n\u001b[0;32m     74\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m     75\u001b[0m         sequences,\n\u001b[0;32m     76\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mTruncationStrategy\u001b[38;5;241m.\u001b[39mONLY_FIRST,\n\u001b[0;32m     80\u001b[0m     )\n\u001b[1;32m---> 82\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_input_names\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     83\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m## Apply softmax on logits\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\qlatent\\qmnli\\qmnli.py:82\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m## Calculate batch entailment probabilities\u001b[39;00m\n\u001b[0;32m     74\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m     75\u001b[0m         sequences,\n\u001b[0;32m     76\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mTruncationStrategy\u001b[38;5;241m.\u001b[39mONLY_FIRST,\n\u001b[0;32m     80\u001b[0m     )\n\u001b[1;32m---> 82\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {k: \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names}\n\u001b[0;32m     83\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m## Apply softmax on logits\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for Q in tqdm(gad_qmnli):\n",
    "    Qs = split_question(Q,\n",
    "                        index=Q.index,\n",
    "                        scales=[Q.scale],\n",
    "                        softmax=[True],\n",
    "                        filters={'unfiltered':{},\n",
    "                                \"positiveonly\":Q().get_filter_for_postive_keywords()\n",
    "                                },\n",
    "                        )\n",
    "    print(Qs[0]._descriptor['Ordinal'])\n",
    "    Qs[0].run(mnli).report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
