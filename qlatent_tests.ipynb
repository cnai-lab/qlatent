{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "from qlatent import *\n",
    "from qlatent.questionnaire_utils import split_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['index'], 'frequency') True unfiltered\n",
      "(['index'], 'frequency') True positiveonly\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qlatent.qabstract.qabstract.QFILTER at 0x1c7bd66ffd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlatent.qmlm.qmlm import *\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "    'never':-4,\n",
    "    'very rarely':-3,\n",
    "    'seldom':-2,\n",
    "    'rarely':-2,\n",
    "    'frequently':2,\n",
    "    'often':2,\n",
    "    'very frequently':3,\n",
    "    'always':4,\n",
    "}\n",
    "\n",
    "class ASIQ2(QMLM):\n",
    "\n",
    "   kw_fairness = [\"fairness\", \"equal chances\", \"equality\"]\n",
    "   kw_favors   = ['special favors', \"privileges\"]\n",
    "   dict_objective = dict_pos_neg(kw_favors, kw_fairness,1)\n",
    "   \n",
    "   index=[\"index\"]  # added\n",
    "   scale=\"frequency\"  # added\n",
    "\n",
    "   def __init__(self, **kwargs):\n",
    "      super().__init__(\n",
    "         template=\"Women are actually seeking for {index} that favor them over men under the guise of asking for equality. It is {frequency} correct.\",\n",
    "         dimensions={\n",
    "                     \"index\":self.dict_objective,\n",
    "                     \"frequency\":frequency_weights\n",
    "         },\n",
    "         descriptor = {\"Questionnair\":\"ASI\",\n",
    "            \"Factor\":\"H\",\n",
    "            \"Ordinal\":2,\n",
    "            \"Original\":'H 2. Many women are actually seeking special favors, such as hiring policies that favor them over men, under the guise of asking for \"equality.\"'\n",
    "         },\n",
    "         **kwargs,\n",
    "      )\n",
    "\n",
    "Q = ASIQ2\n",
    "\n",
    "Qs = split_question(Q,\n",
    "                    index=Q.index,\n",
    "                    scales=[Q.scale],\n",
    "                    softmax=[True],\n",
    "                    filters={'unfiltered':{},\n",
    "                             \"positiveonly\":Q().get_filter_for_postive_keywords()\n",
    "                            },\n",
    "                   )\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "   \n",
    "p = \"distilbert/distilbert-base-uncased\"\n",
    "mlm_pipeline = pipeline(\"fill-mask\", device=device, model=p)\n",
    "mlm_pipeline.model_identifier = p\n",
    "\n",
    "Qs[0].run(mlm_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['index'], 'frequency') True unfiltered\n",
      "(['index'], 'frequency') True positiveonly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qlatent.qabstract.qabstract.QFILTER at 0x1c7c26f6d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlatent.qmnli.qmnli import *\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "    'never':-4,\n",
    "    'very rarely':-3,\n",
    "    'seldom':-2,\n",
    "    'rarely':-2,\n",
    "    'frequently':2,\n",
    "    'often':2,\n",
    "    'very frequently':3,\n",
    "    'always':4,\n",
    "}\n",
    "\n",
    "class SOCQ4(QMNLI):\n",
    "\n",
    "   index=[\"index\"]\n",
    "   scale=\"frequency\"\n",
    "\n",
    "   kw_attitude_neg = [\"meaningless\", \"dull\", \"aimless\", 'boring']\n",
    "   kw_attitude_pos = [\"meaningful\", \"interesting\", \"fulfilling\", 'fascinating']\n",
    "   dict_attitude = dict_pos_neg(kw_attitude_pos,kw_attitude_neg, 1.0)\n",
    "\n",
    "   def __init__(self, **kwargs):\n",
    "      super().__init__(\n",
    "         context_template=\"What goes around me is {index} to me.\",\n",
    "         answer_template=\"It is {frequency} correct.\",\n",
    "         dimensions={\n",
    "            \"frequency\":frequency_weights,\n",
    "            \"index\":self.dict_attitude,\n",
    "         },\n",
    "         descriptor = {\"Questionnair\":\"SOC\",\n",
    "            \"Factor\":\"Meaningfulness\",\n",
    "            \"Ordinal\":4,\n",
    "            \"Original\":\"Do you have the feeling that you donâ€™t really care what goes on around you? \"\n",
    "         },\n",
    "         **kwargs,\n",
    "      )\n",
    "\n",
    "Q = SOCQ4\n",
    "\n",
    "Qs = split_question(Q,\n",
    "                    index=Q.index,\n",
    "                    scales=[Q.scale],\n",
    "                    softmax=[True],\n",
    "                    filters={'unfiltered':{},\n",
    "                             \"positiveonly\":Q().get_filter_for_postive_keywords(),\n",
    "                            },\n",
    "                   )\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "   \n",
    "p = \"typeform/distilbert-base-uncased-mnli\"\n",
    "nli_pipeline = pipeline(\"zero-shot-classification\",device=device, model=p)\n",
    "nli_pipeline.model_identifier = p\n",
    "\n",
    "Qs[0].run(nli_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['emotion'], 'intensifier') True unfiltered\n",
      "(['emotion'], 'intensifier') True positiveonly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qlatent.qabstract.qabstract.QFILTER at 0x1c7c06f7490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlatent.qmnli.qmnli import _QMNLI\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "  'never':-4,\n",
    "  'very rarely':-3,\n",
    "  'seldom':-2,\n",
    "  'rarely':-2,\n",
    "  'frequently':2,\n",
    "  'often':2,\n",
    "  'very frequently':3,\n",
    "  'always':4,\n",
    "}\n",
    "\n",
    "class GAD7Q1(_QMNLI):\n",
    "\n",
    "   def __init__(self, **kwargs):\n",
    "      super().__init__(\n",
    "         context=\"Over the last 2 weeks, I feel {emotion}.\",\n",
    "         template=\"It is {intensifier} correct.\",\n",
    "         emo_pos=['nervous', 'anxious', 'on edge'],\n",
    "         emo_neg=['calm', 'peaceful', 'relaxed'],\n",
    "         intensifiers=frequency_weights,  # added\n",
    "         descriptor = {\"Questionnair\":\"GAD7\",\n",
    "                       \"Factor\":\"GAD\",\n",
    "                       \"Ordinal\":1,\n",
    "                       \"Original\":\"Over the last 2 weeks, how often have you been bothered by the following problems? Feeling nervous, anxious or on edge\",\n",
    "                      },\n",
    "      **kwargs,\n",
    "      )\n",
    "\n",
    "Q = GAD7Q1\n",
    "\n",
    "Qs = split_question(Q,\n",
    "                    index=Q.index,\n",
    "                    scales=[Q.scale],\n",
    "                    softmax=[True],\n",
    "                    filters={'unfiltered':{},\n",
    "                             \"positiveonly\":Q().get_filter_for_postive_keywords(),\n",
    "                            },\n",
    "                   )\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "   \n",
    "p = \"typeform/distilbert-base-uncased-mnli\"\n",
    "nli_pipeline = pipeline(\"zero-shot-classification\",device=device, model=p)\n",
    "nli_pipeline.model_identifier = p\n",
    "\n",
    "Qs[0].run(nli_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['index'], 'frequency') True unfiltered\n",
      "(['index'], 'frequency') True positiveonly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1597: FutureWarning: The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qlatent.qabstract.qabstract.QFILTER at 0x1c7c25bbe10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlatent.qnsp.qnsp import *\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "  'never':-4,\n",
    "  'very rarely':-3,\n",
    "  'seldom':-2,\n",
    "  'rarely':-2,\n",
    "  'frequently':2,\n",
    "  'often':2,\n",
    "  'very frequently':3,\n",
    "  'always':4,\n",
    "}\n",
    "\n",
    "class ASIQ2(QNSP):\n",
    "\n",
    "   kw_fairness = [\"equal chances\", \"equality\", 'fair opportunities']\n",
    "   kw_favors   = ['special favors', \"privileges\", 'preferential treatment']\n",
    "   dict_objective = dict_pos_neg(kw_favors, kw_fairness,1)\n",
    "\n",
    "   def __init__(self, **kwargs):\n",
    "      super().__init__(\n",
    "         prompt='Women seek {index} under the guise of asking for equality.',\n",
    "         next_sentence=\"It is {frequency} correct\",\n",
    "         dimensions={\n",
    "                     \"index\":self.dict_objective,\n",
    "                     \"frequency\":frequency_weights\n",
    "         },\n",
    "         descriptor = {\"Questionnair\":\"ASI\",\n",
    "            \"Factor\":\"H\",\n",
    "            \"Ordinal\":2,\n",
    "            \"Original\":'H 2. Many women are actually seeking special favors, such as hiring policies that favor them over men, under the guise of asking for \"equality.\"'\n",
    "         },\n",
    "         **kwargs,\n",
    "      )\n",
    "\n",
    "Q = ASIQ2\n",
    "\n",
    "Qs = split_question(Q,\n",
    "                    index=[\"index\",],\n",
    "                    scales=['frequency'],\n",
    "                    softmax=[True],\n",
    "                    filters={'unfiltered':{},\n",
    "                             \"positiveonly\":Q().get_filter_for_postive_keywords()\n",
    "                            },\n",
    "                   )\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "   \n",
    "p = \"google-bert/bert-base-uncased\"\n",
    "nsp_pipeline = NextSentencePredictionPipeline(p)\n",
    "nsp_pipeline.model_identifier = p\n",
    "\n",
    "Qs[0].run(nsp_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['index'], 'frequency') True unfiltered\n",
      "(['index'], 'frequency') True positiveonly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<qlatent.qabstract.qabstract.QFILTER at 0x1c7c2b08f90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qlatent.qcola.qcola import *\n",
    "\n",
    "# %pip install protobuf  # added\n",
    "\n",
    "frequency_weights:SCALE = {\n",
    "  'never':-4,\n",
    "  'very rarely':-3,\n",
    "  'seldom':-2,\n",
    "  'rarely':-2,\n",
    "  'frequently':2,\n",
    "  'often':2,\n",
    "  'very frequently':3,\n",
    "  'always':4,\n",
    "}\n",
    "\n",
    "class ASIQ2(QCOLA):\n",
    "\n",
    "   kw_fairness = [\"equal rights\", 'impartiality', 'equality']\n",
    "   kw_favors   = ['special favors', 'privileges', 'preferential treatment']\n",
    "   dict_objective = dict_pos_neg(kw_favors, kw_fairness,1)\n",
    "\n",
    "   def __init__(self, **kwargs):\n",
    "      super().__init__(\n",
    "         template='Women {frequency} seek {index} when asking for equality.',\n",
    "         dimensions={\n",
    "                     \"index\":self.dict_objective,\n",
    "                     \"frequency\":frequency_weights\n",
    "         },\n",
    "         descriptor = {\"Questionnair\":\"ASI\",\n",
    "            \"Factor\":\"H\",\n",
    "            \"Ordinal\":2,\n",
    "            \"Original\":'H 2. Many women are actually seeking special favors, such as hiring policies that favor them over men, under the guise of asking for \"equality.\"'\n",
    "         },\n",
    "         **kwargs,\n",
    "      )\n",
    "\n",
    "Q = ASIQ2\n",
    "\n",
    "Qs = split_question(Q,\n",
    "                    index=[\"index\",],\n",
    "                    scales=['frequency'],\n",
    "                    softmax=[True],\n",
    "                    filters={'unfiltered':{},\n",
    "                             \"positiveonly\":Q().get_filter_for_postive_keywords()\n",
    "                            },\n",
    "                   )\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "   \n",
    "p = \"mrm8488/deberta-v3-small-finetuned-cola\"\n",
    "cola_pipeline = pipeline(\"text-classification\", device=device, model = p)\n",
    "cola_pipeline.model_identifier = p\n",
    "\n",
    "Qs[0].run(cola_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
